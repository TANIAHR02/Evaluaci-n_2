"""
SchoolBot - Asistente Inteligente Escolar
Los 5 Prompts Principales del Sistema

Autor: [Nombre del Estudiante]
Fecha: [Fecha Actual]
Evaluaci√≥n: EP1 - Ingenier√≠a de Soluciones con Inteligencia Artificial
Instituci√≥n: Universidad [Nombre]

Descripci√≥n:
Este m√≥dulo contiene los 5 prompts principales espec√≠ficamente solicitados
para el proyecto SchoolBot del Colegio San Ignacio Digital.
"""

from typing import List, Dict, Any

class MainPrompts:
    """
    Los 5 prompts principales del sistema SchoolBot
    """
    
    @staticmethod
    def prompt_1_system_base() -> str:
        """
        PROMPT 1: System Prompt (base)
        Rol: Asistente institucional
        Par√°metros: temperature=0.1, max_tokens=400
        """
        return """Eres SchoolBot, el asistente virtual oficial del Colegio San Ignacio Digital.

INFORMACI√ìN INSTITUCIONAL:
- Instituci√≥n: Colegio San Ignacio Digital
- Ubicaci√≥n: Santiago, Chile
- Tipo: Particular subvencionado
- Estudiantes: M√°s de 600 alumnos
- Enfoque: Integraci√≥n tecnol√≥gica educativa

INSTRUCCIONES PRINCIPALES:
1. Responde de forma clara, breve y respetuosa
2. Usa √öNICAMENTE informaci√≥n de los documentos internos del colegio
3. Mant√©n un tono profesional pero cercano
4. Dirige a la secretar√≠a para consultas que requieran informaci√≥n personal
5. Si no tienes informaci√≥n suficiente, indica claramente: "No tengo esa informaci√≥n en los documentos disponibles del colegio."

CONTEXTO EDUCATIVO:
- Horarios: Lunes a Viernes, 8:00-16:00 horas
- Idioma: Espa√±ol chileno con terminolog√≠a educativa local
- Usuarios: Estudiantes, apoderados, profesores, personal administrativo

FORMATO DE RESPUESTA:
- Inicia con un saludo apropiado
- Proporciona la informaci√≥n solicitada de manera clara
- Cita la fuente cuando sea relevante
- Termina con una oferta de ayuda adicional

RECUERDA: Tu objetivo es ser √∫til, preciso y mantener la confianza de la comunidad educativa."""
    
    @staticmethod
    def prompt_2_rag_synthesis(retrieved_docs: List[Dict[str, Any]], question: str) -> str:
        """
        PROMPT 2: S√≠ntesis RAG
        Rol: Agente de respuesta
        Par√°metros: temperature=0.3, max_tokens=200
        """
        # Formatear documentos recuperados
        docs_text = ""
        for i, doc in enumerate(retrieved_docs, 1):
            source = doc.get('metadata', {}).get('file_name', 'Documento')
            content = doc.get('text', '')
            docs_text += f"[Fuente {i}: {source}]\n{content}\n\n"
        
        return f"""DOCUMENTOS RECUPERADOS:
{docs_text}

PREGUNTA DEL USUARIO: {question}

INSTRUCCIONES:
1. Usa √öNICAMENTE la informaci√≥n de los documentos recuperados arriba
2. Redacta una respuesta de m√°ximo 150 palabras
3. Cita las fuentes entre corchetes [Fuente X]
4. Si la informaci√≥n no est√° en los documentos, indica claramente que no tienes esa informaci√≥n
5. Mant√©n un tono profesional y educativo
6. Responde en espa√±ol chileno

RESPUESTA:"""
    
    @staticmethod
    def prompt_3_clarification(question: str) -> str:
        """
        PROMPT 3: Clarificaci√≥n
        Rol: Agente de interpretaci√≥n
        Par√°metros: temperature=0.2, max_tokens=150
        """
        return f"""PREGUNTA RECIBIDA: "{question}"

AN√ÅLISIS:
La pregunta parece ambigua o incompleta. Necesito m√°s informaci√≥n para proporcionar una respuesta precisa.

FORMULA 2 PREGUNTAS DE ACLARACI√ìN:

1. [Pregunta espec√≠fica para clarificar el contexto]
2. [Pregunta espec√≠fica para clarificar el detalle]

FORMATO DE RESPUESTA:
"Para poder ayudarte mejor, necesito aclarar algunos detalles:

1. [Tu primera pregunta de aclaraci√≥n]
2. [Tu segunda pregunta de aclaraci√≥n]

Una vez que me proporciones esta informaci√≥n, podr√© darte una respuesta m√°s precisa y √∫til." """
    
    @staticmethod
    def prompt_4_coherence_check(response: str, retrieved_docs: List[Dict[str, Any]]) -> str:
        """
        PROMPT 4: Comprobaci√≥n de coherencia
        Rol: Validador de respuesta
        Par√°metros: temperature=0.0, max_tokens=300
        """
        # Formatear documentos para comparaci√≥n
        docs_summary = ""
        for i, doc in enumerate(retrieved_docs, 1):
            source = doc.get('metadata', {}).get('file_name', 'Documento')
            content = doc.get('text', '')[:200] + "..."
            docs_summary += f"Fuente {i} ({source}): {content}\n"
        
        return f"""RESPUESTA GENERADA:
{response}

DOCUMENTOS DE REFERENCIA:
{docs_summary}

INSTRUCCIONES DE VALIDACI√ìN:
Analiza cada afirmaci√≥n de la respuesta y determina:

1. ¬øEst√° respaldada por los documentos? (S√≠/No)
2. ¬øEl nivel de confianza es apropiado? (Alta/Media/Baja)
3. ¬øHay informaci√≥n incorrecta o inventada? (S√≠/No)
4. ¬øLas citas de fuentes son correctas? (S√≠/No)

FORMATO DE EVALUACI√ìN:
- Afirmaci√≥n 1: Respaldada: [S√≠/No], Confianza: [Alta/Media/Baja]
- Afirmaci√≥n 2: Respaldada: [S√≠/No], Confianza: [Alta/Media/Baja]
- [Continuar para cada afirmaci√≥n]

EVALUACI√ìN GENERAL:
- Precisi√≥n general: [Alta/Media/Baja]
- Coherencia con fuentes: [S√≠/No]
- Recomendaci√≥n: [Aprobar/Revisar/Rechazar]"""
    
    @staticmethod
    def prompt_5_learning_agent(previous_queries: List[Dict[str, Any]]) -> str:
        """
        PROMPT 5: Agente de aprendizaje
        Rol: Agente de mejora continua
        Par√°metros: temperature=0.4, max_tokens=500
        """
        # Formatear consultas anteriores
        queries_text = ""
        for i, query in enumerate(previous_queries, 1):
            queries_text += f"""
Consulta {i}:
- Pregunta: {query.get('question', 'N/A')}
- Respuesta: {query.get('answer', 'N/A')}
- Precisi√≥n: {query.get('accuracy', 'N/A')}
- Fuentes: {query.get('sources', 'N/A')}
- Timestamp: {query.get('timestamp', 'N/A')}
"""
        
        return f"""AN√ÅLISIS DE CONSULTAS ANTERIORES:
{queries_text}

INSTRUCCIONES DE AN√ÅLISIS:
Analiza las 10 consultas anteriores y su precisi√≥n para identificar patrones y oportunidades de mejora.

√ÅREAS DE AN√ÅLISIS:
1. Tipos de consultas m√°s frecuentes
2. Nivel de precisi√≥n promedio
3. Fuentes m√°s utilizadas
4. Patrones de error comunes
5. Consultas que requieren aclaraci√≥n

PROPUESTAS DE MEJORA:

1. PROMPTS:
- [Sugerencias espec√≠ficas para mejorar la formulaci√≥n de prompts]
- [Ajustes en el tono o formato de respuestas]

2. DATOS:
- [Sugerencias para mejorar la calidad de los documentos]
- [√Åreas donde faltan documentos o informaci√≥n]

3. PROCESO:
- [Mejoras en el proceso de recuperaci√≥n de informaci√≥n]
- [Optimizaciones en la s√≠ntesis de respuestas]

4. M√âTRICAS:
- [Nuevas m√©tricas para evaluar el rendimiento]
- [Indicadores de calidad a monitorear]

EVALUACI√ìN GENERAL:
- Precisi√≥n promedio: [X]%
- √Årea de mayor mejora: [Identificar]
- Prioridad de implementaci√≥n: [Alta/Media/Baja]"""

# Ejemplos de uso de los prompts
def demonstrate_prompts():
    """
    Demuestra el uso de los 5 prompts principales
    """
    print("=" * 60)
    print("DEMOSTRACI√ìN DE LOS 5 PROMPTS PRINCIPALES")
    print("=" * 60)
    
    # Prompt 1: System Prompt
    print("\n1. PROMPT 1: SYSTEM PROMPT (BASE)")
    print("-" * 50)
    prompt_1 = MainPrompts.prompt_1_system_base()
    print(f"Longitud: {len(prompt_1)} caracteres")
    print("Contenido:")
    print(prompt_1[:300] + "...")
    
    # Prompt 2: RAG Synthesis
    print("\n2. PROMPT 2: S√çNTESIS RAG")
    print("-" * 50)
    
    # Documentos de ejemplo
    sample_docs = [
        {
            "text": "Las clases se desarrollan de lunes a viernes de 8:00 a 16:00 horas",
            "metadata": {"file_name": "reglamento_escolar.txt"}
        },
        {
            "text": "Las vacaciones de invierno son del 24 de junio al 7 de julio de 2024",
            "metadata": {"file_name": "calendario_academico.txt"}
        }
    ]
    
    question = "¬øCu√°les son los horarios de clases?"
    prompt_2 = MainPrompts.prompt_2_rag_synthesis(sample_docs, question)
    print(f"Pregunta: {question}")
    print(f"Longitud del prompt: {len(prompt_2)} caracteres")
    print("Contenido:")
    print(prompt_2[:400] + "...")
    
    # Prompt 3: Clarificaci√≥n
    print("\n3. PROMPT 3: CLARIFICACI√ìN")
    print("-" * 50)
    
    ambiguous_question = "¬øQu√© necesito para el colegio?"
    prompt_3 = MainPrompts.prompt_3_clarification(ambiguous_question)
    print(f"Pregunta ambigua: {ambiguous_question}")
    print("Contenido:")
    print(prompt_3)
    
    # Prompt 4: Coherencia
    print("\n4. PROMPT 4: COMPROBACI√ìN DE COHERENCIA")
    print("-" * 50)
    
    sample_response = "Las clases empiezan a las 8:00 horas de lunes a viernes seg√∫n el reglamento escolar."
    prompt_4 = MainPrompts.prompt_4_coherence_check(sample_response, sample_docs)
    print(f"Respuesta a validar: {sample_response}")
    print("Contenido:")
    print(prompt_4[:400] + "...")
    
    # Prompt 5: Aprendizaje
    print("\n5. PROMPT 5: AGENTE DE APRENDIZAJE")
    print("-" * 50)
    
    # Consultas de ejemplo
    sample_queries = [
        {
            "question": "¬øCu√°les son los horarios de clases?",
            "answer": "Las clases son de lunes a viernes de 8:00 a 16:00 horas",
            "accuracy": 0.95,
            "sources": ["reglamento_escolar.txt"],
            "timestamp": "2024-03-15 10:30:00"
        },
        {
            "question": "¬øCu√°ndo son las vacaciones?",
            "answer": "Las vacaciones de invierno son del 24 de junio al 7 de julio",
            "accuracy": 0.90,
            "sources": ["calendario_academico.txt"],
            "timestamp": "2024-03-15 11:15:00"
        }
    ]
    
    prompt_5 = MainPrompts.prompt_5_learning_agent(sample_queries)
    print("Contenido:")
    print(prompt_5[:500] + "...")

# Funci√≥n principal
if __name__ == "__main__":
    demonstrate_prompts()
    
    print("\n" + "=" * 60)
    print("RESUMEN DE LOS 5 PROMPTS PRINCIPALES")
    print("=" * 60)
    
    print("\n‚úÖ PROMPT 1: System Prompt (base)")
    print("   - Rol: Asistente institucional")
    print("   - Par√°metros: temperature=0.1, max_tokens=400")
    print("   - Funci√≥n: Define la identidad y comportamiento base de SchoolBot")
    
    print("\n‚úÖ PROMPT 2: S√≠ntesis RAG")
    print("   - Rol: Agente de respuesta")
    print("   - Par√°metros: temperature=0.3, max_tokens=200")
    print("   - Funci√≥n: Sintetiza informaci√≥n de documentos recuperados")
    
    print("\n‚úÖ PROMPT 3: Clarificaci√≥n")
    print("   - Rol: Agente de interpretaci√≥n")
    print("   - Par√°metros: temperature=0.2, max_tokens=150")
    print("   - Funci√≥n: Solicita aclaraciones para preguntas ambiguas")
    
    print("\n‚úÖ PROMPT 4: Comprobaci√≥n de coherencia")
    print("   - Rol: Validador de respuesta")
    print("   - Par√°metros: temperature=0.0, max_tokens=300")
    print("   - Funci√≥n: Valida coherencia entre respuesta y fuentes")
    
    print("\n‚úÖ PROMPT 5: Agente de aprendizaje")
    print("   - Rol: Agente de mejora continua")
    print("   - Par√°metros: temperature=0.4, max_tokens=500")
    print("   - Funci√≥n: Analiza consultas anteriores y propone mejoras")
    
    print("\nüéØ Todos los prompts est√°n optimizados para el contexto educativo")
    print("   del Colegio San Ignacio Digital y listos para su implementaci√≥n.")

